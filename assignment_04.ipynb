{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to manually compute the steps necessary for forward feed and backward propagation of a given neural network with two inputs (i_1, i_2), two hidden layers (h_1, h_2) and two outputs (o_1, o_2). In addition, the hidden layers and outputs are assumed to carry biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights = [0.55, 0.5, -0.25, 0.05, 0.35, 0.4, -0.6, 0.45]\n",
    "init_biases = [0.3, 0.15, -0.2, -0.3]\n",
    "input = [2, 5]\n",
    "output = [5, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 04.1: Forward Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed output o1 =  1.1269349672143838\n",
      "Computed output o2 =  -0.9316301377536094\n",
      "Mean squared error =  11.797544006385948\n"
     ]
    }
   ],
   "source": [
    "net_h1 = input[0] * init_weights[0] + input[1] * init_weights[1] + init_biases[0]\n",
    "net_h2 = input[0] * init_weights[2] + input[1] * init_weights[3] + init_biases[1]\n",
    "\n",
    "def ELU(x):\n",
    "    if x > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return np.exp(x) - 1\n",
    "\n",
    "out_h1 = ELU(net_h1)    \n",
    "out_h2 = ELU(net_h2)\n",
    "\n",
    "net_o1 = out_h1 * init_weights[4] + out_h2 * init_weights[5] + init_biases[2]\n",
    "net_o2 = out_h1 * init_weights[6] + out_h2 * init_weights[7] + init_biases[3]\n",
    "\n",
    "out_o1 = ELU(net_o1)\n",
    "out_o2 = ELU(net_o2)\n",
    "\n",
    "print('Computed output o1 = ', out_o1)\n",
    "print('Computed output o2 = ', out_o2)\n",
    "\n",
    "MSE = (1/2) * ((out_o1 - output[0])**2 + (out_o2 - output[1])**2)\n",
    "print('Mean squared error = ', MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 04.2: Back-propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to apply the gradient descent method to the mean squared error. Let's compute the partial derivatives of MSE w.r.t. to the weights w_i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New computed output o1 =  2.064447974945287\n",
      "New computed output o2 =  -0.9309645844400671\n",
      "Mean squared error =  8.60400954352238\n"
     ]
    }
   ],
   "source": [
    "def dELU(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.exp(x)\n",
    "\n",
    "dMSEdw_5 = (out_o1 - output[0]) * dELU(net_o1) * out_h1\n",
    "dMSEdw_6 = (out_o1 - output[0]) * dELU(net_o1) * out_h2\n",
    "dMSEdw_7 = (out_o2 - output[1]) * dELU(net_o2) * out_h1\n",
    "dMSEdw_8 = (out_o2 - output[1]) * dELU(net_o2) * out_h2\n",
    "\n",
    "dMSEdw_1 = ((out_o1 - output[0]) * dELU(net_o1) * init_weights[4] + (out_o2 - output[1]) * dELU(net_o2) * init_weights[6]) * dELU(net_h1) * input[0]\n",
    "dMSEdw_2 = ((out_o1 - output[0]) * dELU(net_o1) * init_weights[4] + (out_o2 - output[1]) * dELU(net_o2) * init_weights[6]) * dELU(net_h1) * input[1]\n",
    "dMSEdw_3 = ((out_o1 - output[0]) * dELU(net_o1) * init_weights[5] + (out_o2 - output[1]) * dELU(net_o2) * init_weights[7]) * dELU(net_h2) * input[0]\n",
    "dMSEdw_4 = ((out_o1 - output[0]) * dELU(net_o1) * init_weights[5] + (out_o2 - output[1]) * dELU(net_o2) * init_weights[7]) * dELU(net_h2) * input[1]\n",
    "\n",
    "dMSEdw = [globals()[f'dMSEdw_{n}'] for n in range(1,9)]\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "new_weights = [init_weights[n] - learning_rate * dMSEdw[n] for n in range(8)]\n",
    "\n",
    "net_h1_new = input[0] * new_weights[0] + input[1] * new_weights[1] + init_biases[0]\n",
    "net_h2_new = input[0] * new_weights[2] + input[1] * new_weights[3] + init_biases[1]\n",
    "\n",
    "out_h1_new = ELU(net_h1_new)    \n",
    "out_h2_new = ELU(net_h2_new)\n",
    "\n",
    "net_o1_new = out_h1_new * new_weights[4] + out_h2_new * new_weights[5] + init_biases[2]\n",
    "net_o2_new = out_h1_new * new_weights[6] + out_h2_new * new_weights[7] + init_biases[3]\n",
    "\n",
    "out_o1_new = ELU(net_o1_new)\n",
    "out_o2_new = ELU(net_o2_new)\n",
    "\n",
    "print('New computed output o1 = ', out_o1_new)\n",
    "print('New computed output o2 = ', out_o2_new)\n",
    "\n",
    "MSE = (1/2) * ((out_o1_new - output[0])**2 + (out_o2_new - output[1])**2)\n",
    "print('Mean squared error = ', MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the MSE decreased, meaning that the adaption of the weights was successful. Although the predicted output is still far from the goal we want to achieve, this algorithm can now be performed many times and will then yield the desired predictivity. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CPIV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
